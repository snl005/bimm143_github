---
title: "Class 8: Breast Cancer Analysis Mini Project"
author: "Le, Sarah (PID: A18518276)"
format: pdf
toc: true
---

## Background

The goal of this mini-project is to explore a complete analysis using the unsupervised learning techniques covered in our last class. 

The data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets". 

Values in this data set describe characteristics of the cell nuclei present in digitized images of a five needle aspiration (FNA) of a breast mass.

## Data import

Data was downloaded from the class website as a CVS file. 

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
head(wisc.df)

```

The first column `diagnosis` is the expert opinion on the sample (i.e. patient FNA).

```{r}
wisc.df$diagnosis

```

Remove the diagnosis from data for subsequent analysis.

```{r}
wisc.data <- wisc.df[,-1]
dim(wisc.data)
```

Store the diagnosis as a vector for use later when we compare our results to those from experts in the field. 
```{r}
diagnosis <- factor(wisc.df$diagnosis) 
```

## Exploratory data analysis

> Q1. How many observations are in this dataset?

There are `r nrow(wisc.data)` observations/ patients in the dataset.

> Q2. How many of the observations have a malignant diagnosis?

```{r}
table(wisc.df$diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
#colnames(wisc.data)
length(grep("_mean", colnames(wisc.data)))
```

## Principal Component Analysis (PCA)

The `prcomp()` function to do PCA has a `scale= FALSE` default. In general, we nearly always want to set this to TRUE so our analysis is not dominated by columns/ variables in our dataset that have high standard deviation and mean when compared to others just because the units of measurement are on different units/ scales. 

```{r}
wisc.pr <- prcomp(wisc.data, scale= TRUE)
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

Proportion of Variance (PC1): 0.4427.
The first principal component (PC1) captures 44.27% of the total variance in the data.

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

Cumulative Proportion:
PC1	0.4427
PC2	0.6324
PC3	0.7264
3 principal components (PC1–PC3) are required to describe at least 70% of the variance.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

Cumulative Proportion:
PC6	0.8876
PC7	0.9101
7 principal components (PC1–PC7) are required to describe at least 90% of the total variance.

### Interpreting PCA results
A common visualization for PCA results is the so-called biplot.

Create a biplot of the wisc.pr using the biplot() function.

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

The biplot is very cluttered due to overlapping texts with arrows so it makes it too difficult to interpret. There are many variables so it makes this look messy and uninformative. 

```{r}
biplot(wisc.pr)
```

Lets generate a more standard scatter plot of each observation along principal components 1 and 2 (i.e. a plot of PC1 vs PC2 available as the first two columns of wisc.pr$x) and color the points by the diagnosis (available in the diagnosis vector you created earlier).

```{r}
# Scatter plot observations by components 1 and 2
plot( wisc.pr$x[,1], wisc.pr$x[,2], col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

PC1 vs PC2 shows clear separation between malignant and benign samples while PC1 vs PC3 shows less separation which shows that PC2 explains more useful information comparing to PC3.

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[,1], wisc.pr$x[,3], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```

The main PC result figure is called a "score plot" or "PC plot" or "ordination plot"...

```{r}
library(ggplot2)

ggplot(wisc.pr$x, aes(PC1, PC2, col= diagnosis)) +
  geom_point()
```

### PCA Scree-plot

A plot of how much variance each PC captures. We can get this from `wisc.pr$sdev` or from the output of `summary(wisc.pr)`. 

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var /sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

### Communicating PCA results 

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean", 1]
```


> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

We need 5 PCs in order to get 80% of the variance of the data. 

```{r}
summary(wisc.pr)
```

## Hierachical clustering

Just clustering the original data is not very informative or helpful. 

```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist)
```

View the clustering dendrogram result.

```{r}
plot(wisc.hclust)
```

### Combining methods (PCA and Clustering)

Clustering the original data was not very productive. The PCA results looked promising. Here we combine these methods by clustering from our PCA results. In other words, "clustering in PC space"...

```{r}
## Take the first 3 PCs
dist.pc <- dist(wisc.pr$x[, 1:3])
wisc.pr.hclust <- hclust(dist.pc, method= "ward.D2")
```

View the tree...

### Results of hierarchical clustering

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters? 

Height of approximately 20. 

```{r}
plot(wisc.hclust)
abline(h=20, col="red", lty=2)
```

### Selecting number of clusters

Use `cutree()` to cut the tree so that it has 4 clusters. Assign the output to the variable wisc.hclust.clusters.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters)
```

Use the `table()` function to compare the cluster membership to the actual diagnoses.

```{r}
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

By cutting into a different number of clusters between 2 and 10, 4 clusters already give good separation between malignant (M) and benign (B) samples where cluster 1 mainly has M and cluster 3 has mostly B so 4 clusters already remain the best choice for separation for cluster vs diagnosis match. 

### Using different methods

There are number of different “methods” that can use to combine points during the hierarchical clustering procedure. These include "single", "complete", "average" and "ward.D2".


> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

The `ward.D2` method gives the best results as it minimizes the variance within the clusters to have well separated groups which makes it easy to see the M and B samples compared to other methods.

## K-means clustering

K-means clustering and comparing results

```{r}
wisc.km <- kmeans(scale(wisc.data), centers= 2, nstart= 20)
```

```{r}
table(wisc.km$cluster, diagnosis)
```

> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?

K-means separates the two diagnoses well, with 1 cluster mainly corresponds to Malignant and the other aligns with Benign. However, there is still some overlap and it shows that the hclust still provides a slightly better separation between the 2 samples.

```{r}
table(wisc.hclust.clusters, wisc.km$cluster)
```


### Combining methods (PCA and Clustering)

To get our clustering membership vector (i.e. our main clustering result) we "cut" the tree at a desired height or to yield a desired number of "k" groups.

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

How does this clustering grps compare to the expert diagnosis?

```{r}
table(grps, diagnosis)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
g <- as.factor(grps)
levels(g)
```

```{r}
g <- relevel(g,2)
levels(g)
```

```{r}
# Plot using our re-ordered factor 
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
library(rgl)
plot3d(wisc.pr$x[,1:3], xlab="PC 1", ylab="PC 2", zlab="PC 3", cex=1.5, size=1, type="s", col=grps)
```

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method="ward.D2")
```

```{r}
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

The new hierarchical model with 2 clusters mostly separates malignant and benign samples correctly with each cluster contains mostly of each sample.

```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

Both methods separate pretty well but the hierarchical clustering `Ward.D2` produces a slightly clearer grouping with fewer misclassified samples compared to `K-means`.

```{r}
table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```

## Sensitivity/ Specificity

Sensitivity refers to a test’s ability to correctly detect ill patients who do have the condition. In example here the sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN).

Specificity relates to a test’s ability to correctly reject healthy patients without a condition. In example specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN).

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

The ward.D2 hierarchical clustering model produces the best specificity with around 96.6% and high sensitivity around 96.5% meaning that this has high accuracy in identifying both malignant and benign so this will be the most reliable clustering method for separating 2 samples in the data set.

```{r}
TP <- 165
FN <- 6
TN <- 343
FP <- 12

# Sensitivity and Specificity calculations:
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)

sensitivity
specificity
```


## Prediction

We can use our PCA model for prediction with new input patient samples.

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

In the plot, patient #2 looks like it falls closer to the Malignant cluster (red) where the patient #1 lies near the benign (black) so we should prioritize patient #2 for follow-up. 
